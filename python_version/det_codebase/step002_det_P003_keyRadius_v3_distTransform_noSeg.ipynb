{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages\n",
    "------------------\n",
    "\n",
    "Some packages are installed automatically if you use Anaconda. As pytorch is used here, you are expected to install that in your machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, random, time, copy\n",
    "from skimage import io, transform, morphology, feature\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "import scipy.io as sio\n",
    "from scipy import misc\n",
    "from scipy import ndimage, signal\n",
    "import scipy\n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from skimage import data, img_as_float\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "#sys.path.append('/home/skong2/project/dpff4ldl')\n",
    "#from utils.metrics import *\n",
    "#from losses import *\n",
    "\n",
    "from utils.flow_functions import *\n",
    "from utils.dataset import *\n",
    "from utils.network_arch import *\n",
    "from utils.trainval_detSegDistTransform_noSeg import *\n",
    "\n",
    "import warnings # ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup config parameters\n",
    " -----------------\n",
    " \n",
    " There are several things to setup, like which GPU to use, where to read images and save files, etc. Please read and understand this. By default, you should be able to run this script smoothly by changing nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here define the path, which is used to save the log and trained model in training process\n",
    "\n",
    "project_name = 'step002_det_P003_keyRadius_v3_distTransform_noSeg' \n",
    "\n",
    "# cpu or cuda\n",
    "device ='cpu'\n",
    "if torch.cuda.is_available(): \n",
    "    device='cuda:1'\n",
    "print(device)\n",
    "\n",
    "freqShow = 20\n",
    "weight_reg = 2.0\n",
    "weight_background = 0.1\n",
    "\n",
    "#model parameters\n",
    "batch_size = 10\n",
    "newSize = [512, 512]\n",
    "total_epoch_num = 500  # total number of epoch in training\n",
    "base_lr = 0.0005      # base learning rate/\n",
    "scaleList = [0]      # the number of output layer for U-net\n",
    "#scale = [0,1,2,3]      # the number of output layer for U-net\n",
    "\n",
    "\n",
    "exp_dir = './exp' # experiment directory, used for reading the init model\n",
    "save_dir = os.path.join(exp_dir, project_name) # where to save the log file and trained models.\n",
    "if not os.path.exists(save_dir): \n",
    "    os.makedirs(save_dir)\n",
    "log_filename = os.path.join(save_dir, 'train.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objDemoShowFlow = DemoShowFlow() # height=int(Y.max()), width=int(Y.max())\n",
    "plt.imshow(objDemoShowFlow.FlowColorChart)\n",
    "#plt.imshow(objDemoShowFlow.FlowColorChartNoAxes)\n",
    "#misc.imsave(os.path.join(save_dir, 'colorchar.png'.format(idx)), objDemoShowFlow.FlowColorChart*255, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = '/home/skong2/restore/dataset/pollenProject_dataset_part1'\n",
    "path_to_annotCombo = '/home/skong2/restore/dataset/pollenProject_dataset_annotationCombo'\n",
    "with open('dbinfo.plk', 'rb') as handle:\n",
    "    dbinfo = pickle.load(handle)    \n",
    "#dbinfo.keys(), len(dbinfo['train_det_list']), len(dbinfo['test_det_list'])\n",
    "\n",
    "det_datasets = {set_name: PollenDet(path_to_image=path_to_image,\n",
    "                                    path_to_annot=path_to_annotCombo,\n",
    "                                    dbinfo=dbinfo,\n",
    "                                    size=newSize, \n",
    "                                    set_name=set_name)\n",
    "                for set_name in ['train', 'test']}\n",
    "\n",
    "\n",
    "dataloaders = {set_name: DataLoader(det_datasets[set_name],                                    \n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=set_name=='train', \n",
    "                                    num_workers=4) # num_work can be set to batch_size\n",
    "               for set_name in ['train', 'test']}\n",
    "\n",
    "print(len(det_datasets['train']), len(det_datasets['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initModel = PollenDet_SegKeyRadius(34, scaleList=scaleList, pretrained=True)\n",
    "# tmpmodel = PollenDet_SegDistTransform(34, scaleList=scaleList, pretrained=True)\n",
    "\n",
    "# initModel_dict = initModel.state_dict()\n",
    "# tmpmodel_dict = tmpmodel.state_dict()\n",
    "# pretrained_dict = {k: v for k, v in tmpmodel_dict.items() if k not in initModel_dict}\n",
    "\n",
    "# pretrained_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## init model ###################\n",
    "initModel = PollenDet_SegDistTransform(34, scaleList=scaleList, pretrained=True)\n",
    "initModel.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for regression with masking\n",
    "class MaskWeightedL1(nn.Module):\n",
    "    def __init__(self, wBG=0.5, wFactor=1):\n",
    "        super(MaskWeightedL1, self).__init__()        \n",
    "        self.wBG = wBG\n",
    "        self.wFactor = wFactor\n",
    "        \n",
    "    def forward(self, inputs, target, segMask, overlapMask=0): \n",
    "        N, C, H, W = inputs.shape\n",
    "        output = inputs - target\n",
    "        totalNum = H * W * N\n",
    "        output = torch.abs(output)\n",
    "        output = torch.mean(output, 1, keepdim=True)\n",
    "                \n",
    "        output = output * (segMask + self.wBG) * (1-overlapMask)\n",
    "        \n",
    "        lossValue = output.sum() / totalNum\n",
    "        return lossValue*self.wFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for (binary) segmentation\n",
    "weight = torch.ones(2)\n",
    "weight[0] = 0.5\n",
    "weight = weight.to(device)\n",
    "#lossFunc_seg = nn.CrossEntropyLoss(weight=weight, reduction='elementwise_mean')\n",
    "lossFunc_seg = nn.BCELoss(reduction='mean')\n",
    "\n",
    "lossFunc_reg = MaskWeightedL1(wBG=weight_background, wFactor=weight_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([{'params': initModel.encoder.parameters()},\n",
    "                        {'params': initModel.decoder.parameters()}], \n",
    "                       lr=base_lr, weight_decay=0.0005) \n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=int(total_epoch_num/4), gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## start training ###################\n",
    "fn = open(log_filename,'w')\n",
    "fn.write(log_filename+'\\t'+device+'\\n\\n')\n",
    "#fn.write(path.basename(__file__)+'\\n\\n')\n",
    "fn.close()\n",
    "file_to_note_bestModel = os.path.join(save_dir,'note_bestModel.log')\n",
    "fn = open(file_to_note_bestModel, 'w')\n",
    "fn.write('Record of best models on the way.\\n')\n",
    "fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(initModel, dataloaders, \n",
    "                       lossFunc_seg, lossFunc_reg,\n",
    "                       optimizer, exp_lr_scheduler,\n",
    "                       scaleList=scaleList,\n",
    "                       num_epochs=total_epoch_num, \n",
    "                       work_dir=save_dir, \n",
    "                       device=device,\n",
    "                       freqShow=freqShow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Leaving Blank\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
